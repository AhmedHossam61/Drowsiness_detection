{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb24b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found driver images: ['Ahmed.jpg', 'Bill.jpeg', 'Elon.jpeg', 'Mohamed Ali.jpg']\n",
      "Authorized drivers: ['Ahmed', 'Bill', 'Elon', 'Mohamed Ali']\n",
      "Successfully encoded 4 driver faces\n",
      "Drowsiness detection system initialized\n",
      "Audio system ready - Using: Untitled (1).mp3\n",
      "=== INTEGRATED DRIVER SAFETY SYSTEM ===\n",
      "Phase 1: Security Verification\n",
      "Phase 2: Drowsiness Monitoring\n",
      "Press 'q' to quit at any time\n",
      "Alert sound: Untitled (1).mp3\n",
      "\n",
      "=== SECURITY VERIFIED: AHMED ===\n",
      "Switching to drowsiness monitoring...\n",
      "\n",
      "Driver Safety System terminated.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Integrated Driver Security and Drowsiness Detection System\n",
    "\n",
    "This system combines:\n",
    "1. Face recognition security verification (runs first)\n",
    "2. Driver drowsiness and yawning detection (runs after security verification)\n",
    "\n",
    "Requirements:\n",
    "1. Install packages: pip install opencv-python dlib numpy scipy pygame face-recognition\n",
    "2. Download shape_predictor_68_face_landmarks.dat from http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\n",
    "3. Create 'Images_sec' folder with authorized driver photos (e.g., Ahmed.jpg, Bill.jpeg, etc.)\n",
    "4. Place your MP3 alert file \"Untitled (1).mp3\" in the same directory\n",
    "5. Ensure webcam is connected and working\n",
    "\n",
    "Usage:\n",
    "- Run the script and position your face clearly in front of the camera\n",
    "- First, the security system will verify your identity (needs 2 consecutive verifications)\n",
    "- After successful verification, drowsiness monitoring begins automatically\n",
    "- The system will play \"Untitled (1).mp3\" when drowsiness or yawning is detected\n",
    "- Press 'q' to quit at any time\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import pygame\n",
    "import time\n",
    "import sys\n",
    "import face_recognition\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "class IntegratedDriverSafetySystem:\n",
    "    def __init__(self, security_images_path=\"Images_sec\", mp3_filename=\"Untitled (1).mp3\"):\n",
    "        # Security system initialization\n",
    "        self.security_images_path = security_images_path\n",
    "        self.authorized_drivers = []\n",
    "        self.driver_names = []\n",
    "        self.load_authorized_drivers()\n",
    "        \n",
    "        # Drowsiness detection initialization\n",
    "        self.detector = None\n",
    "        self.predictor = None\n",
    "        self.init_drowsiness_detector()\n",
    "        \n",
    "        # System state\n",
    "        self.security_verified = False\n",
    "        self.verified_driver_name = \"\"\n",
    "        self.consecutive_verifications = 0\n",
    "        self.last_verified_name = \"\"\n",
    "        \n",
    "        # Audio setup\n",
    "        self.mp3_file = mp3_filename\n",
    "        self.setup_audio()\n",
    "        \n",
    "        # Drowsiness detection parameters\n",
    "        self.LEFT_EYE = [36, 37, 38, 39, 40, 41]\n",
    "        self.RIGHT_EYE = [42, 43, 44, 45, 46, 47]\n",
    "        self.MOUTH = [48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]\n",
    "        \n",
    "        # Thresholds\n",
    "        self.EYE_AR_THRESH = 0.25\n",
    "        self.MOUTH_AR_THRESH = 0.7\n",
    "        self.EYE_AR_CONSEC_FRAMES = 20\n",
    "        self.YAWN_CONSEC_FRAMES = 15\n",
    "        \n",
    "        # Counters for drowsiness detection\n",
    "        self.eye_counter = 0\n",
    "        self.yawn_counter = 0\n",
    "        self.drowsy_alert = False\n",
    "        self.yawn_alert = False\n",
    "    \n",
    "    def load_authorized_drivers(self):\n",
    "        \"\"\"Load and encode authorized driver faces\"\"\"\n",
    "        try:\n",
    "            driver_list = os.listdir(self.security_images_path)\n",
    "            print(f\"Found driver images: {driver_list}\")\n",
    "            \n",
    "            images = []\n",
    "            for driver_file in driver_list:\n",
    "                img_path = os.path.join(self.security_images_path, driver_file)\n",
    "                current_img = cv2.imread(img_path)\n",
    "                if current_img is not None:\n",
    "                    images.append(current_img)\n",
    "                    self.driver_names.append(os.path.splitext(driver_file)[0])\n",
    "            \n",
    "            print(f\"Authorized drivers: {self.driver_names}\")\n",
    "            \n",
    "            # Encode faces\n",
    "            for img in images:\n",
    "                img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                encodings = face_recognition.face_encodings(img_rgb)\n",
    "                if encodings:\n",
    "                    self.authorized_drivers.append(encodings[0])\n",
    "                else:\n",
    "                    print(\"Warning: Could not encode face in one of the images\")\n",
    "            \n",
    "            print(f\"Successfully encoded {len(self.authorized_drivers)} driver faces\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading authorized drivers: {e}\")\n",
    "            print(\"Make sure 'Images_sec' folder exists with driver photos\")\n",
    "    \n",
    "    def init_drowsiness_detector(self):\n",
    "        \"\"\"Initialize dlib components for drowsiness detection\"\"\"\n",
    "        try:\n",
    "            self.detector = dlib.get_frontal_face_detector()\n",
    "            self.predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "            print(\"Drowsiness detection system initialized\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing drowsiness detector: {e}\")\n",
    "            print(\"Make sure 'shape_predictor_68_face_landmarks.dat' is available\")\n",
    "    \n",
    "    def setup_audio(self):\n",
    "        \"\"\"Setup audio system for alerts\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.alert_sound = pygame.mixer.Sound(self.mp3_file)\n",
    "            print(f\"Audio system ready - Using: {self.mp3_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Audio setup failed: {e}\")\n",
    "            print(\"Will use system beep as fallback\")\n",
    "            self.alert_sound = None\n",
    "    \n",
    "    def play_alert(self):\n",
    "        \"\"\"Play alert sound\"\"\"\n",
    "        if self.alert_sound:\n",
    "            self.alert_sound.play()\n",
    "        else:\n",
    "            print('\\a')  # System beep\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    def security_verification(self, frame):\n",
    "        \"\"\"Handle security verification phase\"\"\"\n",
    "        # Resize for faster processing\n",
    "        small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "        rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Find faces and encodings\n",
    "        face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "        \n",
    "        current_frame_verified = False\n",
    "        current_verified_name = \"\"\n",
    "        \n",
    "        for face_encoding, face_location in zip(face_encodings, face_locations):\n",
    "            # Compare with authorized drivers\n",
    "            matches = face_recognition.compare_faces(self.authorized_drivers, face_encoding, tolerance=0.6)\n",
    "            face_distances = face_recognition.face_distance(self.authorized_drivers, face_encoding)\n",
    "            \n",
    "            if len(face_distances) > 0:\n",
    "                best_match_index = np.argmin(face_distances)\n",
    "                \n",
    "                if matches[best_match_index]:\n",
    "                    name = self.driver_names[best_match_index].upper()\n",
    "                    current_frame_verified = True\n",
    "                    current_verified_name = name\n",
    "                    \n",
    "                    # Check consecutive verifications\n",
    "                    if name == self.last_verified_name:\n",
    "                        self.consecutive_verifications += 1\n",
    "                    else:\n",
    "                        self.consecutive_verifications = 1\n",
    "                        self.last_verified_name = name\n",
    "                    \n",
    "                    # Draw verification info\n",
    "                    top, right, bottom, left = face_location\n",
    "                    top *= 4\n",
    "                    right *= 4\n",
    "                    bottom *= 4\n",
    "                    left *= 4\n",
    "                    \n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                    cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0), cv2.FILLED)\n",
    "                    cv2.putText(frame, f\"{name} VERIFIED\", (left + 6, bottom - 6), \n",
    "                              cv2.FONT_HERSHEY_COMPLEX, 0.8, (255, 255, 255), 2)\n",
    "                    \n",
    "                    # Check if verification complete\n",
    "                    if self.consecutive_verifications >= 2:\n",
    "                        self.security_verified = True\n",
    "                        self.verified_driver_name = name\n",
    "                        return True\n",
    "        \n",
    "        # Reset if no verification in current frame\n",
    "        if not current_frame_verified and self.consecutive_verifications > 0:\n",
    "            self.consecutive_verifications = 0\n",
    "            self.last_verified_name = \"\"\n",
    "        \n",
    "        # Display verification progress\n",
    "        if self.consecutive_verifications > 0:\n",
    "            cv2.putText(frame, f\"Verifications: {self.consecutive_verifications}/2\", \n",
    "                       (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        # Display instructions\n",
    "        cv2.putText(frame, \"SECURITY VERIFICATION\", (50, 100), \n",
    "                   cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "        cv2.putText(frame, \"Look directly at camera\", (50, 130), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def eye_aspect_ratio(self, eye):\n",
    "        \"\"\"Calculate eye aspect ratio\"\"\"\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "    \n",
    "    def mouth_aspect_ratio(self, mouth):\n",
    "        \"\"\"Calculate mouth aspect ratio\"\"\"\n",
    "        A = dist.euclidean(mouth[2], mouth[10])\n",
    "        B = dist.euclidean(mouth[4], mouth[8])\n",
    "        C = dist.euclidean(mouth[0], mouth[6])\n",
    "        mar = (A + B) / (2.0 * C)\n",
    "        return mar\n",
    "    \n",
    "    def extract_landmarks(self, gray, rect):\n",
    "        \"\"\"Extract facial landmarks\"\"\"\n",
    "        shape = self.predictor(gray, rect)\n",
    "        coords = np.zeros((68, 2), dtype=\"int\")\n",
    "        \n",
    "        for i in range(0, 68):\n",
    "            coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "        \n",
    "        return coords\n",
    "    \n",
    "    def drowsiness_monitoring(self, frame):\n",
    "        \"\"\"Handle drowsiness monitoring phase\"\"\"\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        faces = self.detector(gray, 0)\n",
    "        \n",
    "        for face in faces:\n",
    "            landmarks = self.extract_landmarks(gray, face)\n",
    "            \n",
    "            # Extract eye and mouth coordinates\n",
    "            left_eye = landmarks[self.LEFT_EYE]\n",
    "            right_eye = landmarks[self.RIGHT_EYE]\n",
    "            mouth = landmarks[self.MOUTH]\n",
    "            \n",
    "            # Calculate aspect ratios\n",
    "            left_ear = self.eye_aspect_ratio(left_eye)\n",
    "            right_ear = self.eye_aspect_ratio(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "            \n",
    "            # Draw contours\n",
    "            cv2.drawContours(frame, [cv2.convexHull(left_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(right_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Drowsiness detection\n",
    "            if ear < self.EYE_AR_THRESH:\n",
    "                self.eye_counter += 1\n",
    "                if self.eye_counter >= self.EYE_AR_CONSEC_FRAMES:\n",
    "                    if not self.drowsy_alert:\n",
    "                        self.drowsy_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                self.eye_counter = 0\n",
    "                self.drowsy_alert = False\n",
    "            \n",
    "            # Yawning detection\n",
    "            if mar > self.MOUTH_AR_THRESH:\n",
    "                self.yawn_counter += 1\n",
    "                if self.yawn_counter >= self.YAWN_CONSEC_FRAMES:\n",
    "                    if not self.yawn_alert:\n",
    "                        self.yawn_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                self.yawn_counter = 0\n",
    "                self.yawn_alert = False\n",
    "            \n",
    "            # Display metrics\n",
    "            cv2.putText(frame, f\"Driver: {self.verified_driver_name}\", (10, 30),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"EAR: {ear:.2f}\", (10, 60),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"MAR: {mar:.2f}\", (10, 90),\n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Alert messages\n",
    "            if self.drowsy_alert:\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 130),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "                cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 10)\n",
    "            \n",
    "            if self.yawn_alert:\n",
    "                cv2.putText(frame, \"YAWNING DETECTED!\", (10, 170),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 3)\n",
    "    \n",
    "    def run_system(self):\n",
    "        \"\"\"Main system loop\"\"\"\n",
    "        cap = cv2.VideoCapture(0)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        print(\"=== INTEGRATED DRIVER SAFETY SYSTEM ===\")\n",
    "        print(\"Phase 1: Security Verification\")\n",
    "        print(\"Phase 2: Drowsiness Monitoring\")\n",
    "        print(\"Press 'q' to quit at any time\")\n",
    "        print(f\"Alert sound: {self.mp3_file}\")\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            # Flip frame for mirror effect\n",
    "            frame = cv2.flip(frame, 1)\n",
    "            \n",
    "            if not self.security_verified:\n",
    "                # Security verification phase\n",
    "                verification_complete = self.security_verification(frame)\n",
    "                \n",
    "                if verification_complete:\n",
    "                    # Show success message\n",
    "                    cv2.rectangle(frame, (50, 200), (600, 300), (0, 255, 0), cv2.FILLED)\n",
    "                    cv2.putText(frame, \"ACCESS GRANTED!\", (80, 230), \n",
    "                               cv2.FONT_HERSHEY_COMPLEX, 1.2, (255, 255, 255), 3)\n",
    "                    cv2.putText(frame, f\"Welcome {self.verified_driver_name}\", (80, 270), \n",
    "                               cv2.FONT_HERSHEY_COMPLEX, 1, (255, 255, 255), 2)\n",
    "                    cv2.imshow('Driver Safety System', frame)\n",
    "                    cv2.waitKey(2000)  # Show for 2 seconds\n",
    "                    \n",
    "                    print(f\"\\n=== SECURITY VERIFIED: {self.verified_driver_name} ===\")\n",
    "                    print(\"Switching to drowsiness monitoring...\")\n",
    "                    time.sleep(1)\n",
    "            else:\n",
    "                # Drowsiness monitoring phase\n",
    "                self.drowsiness_monitoring(frame)\n",
    "            \n",
    "            # Common display elements\n",
    "            cv2.putText(frame, \"Press 'q' to quit\", (10, frame.shape[0] - 20),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "            \n",
    "            # System status\n",
    "            if self.security_verified:\n",
    "                cv2.putText(frame, \"STATUS: MONITORING\", (10, frame.shape[0] - 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, \"STATUS: VERIFYING\", (10, frame.shape[0] - 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "            \n",
    "            cv2.imshow('Driver Safety System', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        if self.alert_sound:\n",
    "            pygame.mixer.quit()\n",
    "        \n",
    "        print(\"\\nDriver Safety System terminated.\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the integrated system\"\"\"\n",
    "    try:\n",
    "        system = IntegratedDriverSafetySystem()\n",
    "        system.run_system()\n",
    "    except Exception as e:\n",
    "        print(f\"System error: {e}\")\n",
    "        print(\"Please check all requirements are installed and files are in place\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d87e2daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From c:\\Users\\ahmedhoss\\anaconda3\\envs\\Py_11\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Drowsiness detection system initialized with MediaPipe Face Mesh\n",
      "Audio system ready - Using: Untitled (1).mp3\n",
      "\n",
      "=== INTEGRATED DRIVER SAFETY SYSTEM ===\n",
      "Phase 1: Security Verification (Bypassed)\n",
      "Phase 2: Drowsiness Monitoring\n",
      "Using webcam for live feed.\n",
      "Alert sound: Untitled (1).mp3\n",
      "Calibration complete. Baseline EAR: 1.37, New EAR Thresh: 1.03\n",
      "Baseline MAR: 1.14, New MAR Thresh: 1.43\n",
      "\n",
      "Driver Safety System terminated.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Integrated Driver Security and Drowsiness Detection System\n",
    "\n",
    "This system combines:\n",
    "1. Face recognition security verification (runs first)\n",
    "2. Driver drowsiness and yawning detection (runs after security verification)\n",
    "\n",
    "Requirements:\n",
    "1. Install packages: pip install opencv-python numpy scipy pygame mediapipe\n",
    "2. Create 'Images_sec' folder with authorized driver photos (e.g., Ahmed.jpg, Bill.jpeg, etc.)\n",
    "3. Place your MP3 alert file \"Untitled (1).mp3\" in the same directory\n",
    "4. Ensure webcam is connected and working\n",
    "\n",
    "Usage:\n",
    "- Run the script and position your face clearly in front of the camera\n",
    "- First, the security system will verify your identity (needs 2 consecutive verifications)\n",
    "- After successful verification, drowsiness monitoring begins automatically\n",
    "- The system will play \"Untitled (1).mp3\" when drowsiness or yawning is detected\n",
    "- Press 'q' to quit at any time\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import pygame\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "import mediapipe as mp\n",
    "\n",
    "class IntegratedDriverSafetySystem:\n",
    "    def __init__(self, security_images_path=\"Images_sec\", mp3_filename=\"Untitled (1).mp3\"):\n",
    "        # Security system initialization\n",
    "        self.security_images_path = security_images_path\n",
    "        self.authorized_drivers = [] # This will store face encodings if we re-implement face recognition\n",
    "        self.driver_names = []\n",
    "        # For simplicity, removing face recognition for now to focus on drowsiness\n",
    "        # self.load_authorized_drivers() \n",
    "        \n",
    "        # Drowsiness detection initialization\n",
    "        self.face_mesh = None\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.init_drowsiness_detector()\n",
    "        \n",
    "        # System state\n",
    "        self.security_verified = True # Auto-verify security for now\n",
    "        self.verified_driver_name = \"Driver\"\n",
    "        self.consecutive_verifications = 0\n",
    "        self.last_verified_name = \"\"\n",
    "        \n",
    "        # Audio setup\n",
    "        self.mp3_file = mp3_filename\n",
    "        self.setup_audio()\n",
    "        \n",
    "        # Drowsiness detection parameters (MediaPipe indices)\n",
    "        # These indices are for the 468 landmarks provided by MediaPipe Face Mesh\n",
    "        # Left eye landmarks (approximate, based on common EAR implementations)\n",
    "        self.LEFT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "        self.RIGHT_EYE = [133, 173, 157, 158, 159, 160, 161, 246, 7, 33, 163, 144, 145, 153, 154, 155]\n",
    "        # Mouth landmarks (approximate, for MAR calculation)\n",
    "        self.MOUTH = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 309]\n",
    "\n",
    "        # Thresholds (initial values, will be dynamically adjusted)\n",
    "        self.EYE_AR_THRESH = 0.25\n",
    "        self.MOUTH_AR_THRESH = 0.7\n",
    "        self.EYE_AR_CONSEC_FRAMES = 20\n",
    "        self.YAWN_CONSEC_FRAMES = 15\n",
    "        \n",
    "        # Counters for drowsiness detection\n",
    "        self.eye_counter = 0\n",
    "        self.yawn_counter = 0\n",
    "        self.drowsy_alert = False\n",
    "        self.yawn_alert = False\n",
    "\n",
    "        # New attributes for dynamic thresholding and temporal analysis\n",
    "        self.baseline_ear = None\n",
    "        self.baseline_mar = None\n",
    "        self.ear_history = deque(maxlen=60) # Store last 60 EAR values (approx 2 seconds at 30 FPS)\n",
    "        self.blink_duration_frames = 0\n",
    "        self.blink_count = 0\n",
    "        self.last_blink_time = time.time()\n",
    "        self.calibration_complete = False\n",
    "        self.calibration_frames_collected = 0\n",
    "        self.CALIBRATION_DURATION_SECONDS = 5 # Calibrate for 5 seconds\n",
    "        self.CALIBRATION_EAR_SAMPLES = []\n",
    "        self.CALIBRATION_MAR_SAMPLES = []\n",
    "\n",
    "    def load_authorized_drivers(self):\n",
    "        \"\"\"Load and encode authorized driver faces\"\"\"\n",
    "        # This method is currently not used as face recognition is temporarily removed.\n",
    "        pass\n",
    "    \n",
    "    def init_drowsiness_detector(self):\n",
    "        \"\"\"Initialize MediaPipe Face Mesh for drowsiness detection\"\"\"\n",
    "        try:\n",
    "            self.face_mesh = self.mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "            print(\"Drowsiness detection system initialized with MediaPipe Face Mesh\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing drowsiness detector with MediaPipe: {e}\")\n",
    "            print(\"Make sure MediaPipe is installed and working correctly.\")\n",
    "    \n",
    "    def setup_audio(self):\n",
    "        \"\"\"Setup audio system for alerts\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.alert_sound = pygame.mixer.Sound(self.mp3_file)\n",
    "            print(f\"Audio system ready - Using: {self.mp3_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Audio setup failed: {e}\")\n",
    "            print(\"Will use system beep as fallback\")\n",
    "            self.alert_sound = None\n",
    "    \n",
    "    def play_alert(self):\n",
    "        \"\"\"Play alert sound\"\"\"\n",
    "        if self.alert_sound:\n",
    "            self.alert_sound.play()\n",
    "        else:\n",
    "            print('\\a')  # System beep\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    def security_verification(self, frame):\n",
    "        \"\"\"Handle security verification phase\"\"\"\n",
    "        # This method is currently bypassed for simplicity to focus on drowsiness detection.\n",
    "        # In a real application, this would involve face detection and recognition.\n",
    "        cv2.putText(frame, \"SECURITY VERIFICATION BYPASSED\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Drowsiness monitoring starting...\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        return True\n",
    "    \n",
    "    def eye_aspect_ratio(self, eye):\n",
    "        \"\"\"Calculate eye aspect ratio\"\"\"\n",
    "        # Compute the Euclidean distances between the two sets of\n",
    "        # vertical eye landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        # Compute the Euclidean distance between the horizontal\n",
    "        # eye landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "    \n",
    "    def mouth_aspect_ratio(self, mouth):\n",
    "        \"\"\"Calculate mouth aspect ratio\"\"\"\n",
    "        # Compute the Euclidean distances between the two sets of\n",
    "        # vertical mouth landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(mouth[2], mouth[10])\n",
    "        B = dist.euclidean(mouth[4], mouth[8])\n",
    "        # Compute the Euclidean distance between the horizontal\n",
    "        # mouth landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(mouth[0], mouth[6])\n",
    "        # Compute the mouth aspect ratio\n",
    "        mar = (A + B) / (2.0 * C)\n",
    "        return mar\n",
    "    \n",
    "    def extract_landmarks(self, frame):\n",
    "        \"\"\"Extract facial landmarks using MediaPipe Face Mesh\"\"\"\n",
    "        h, w, c = frame.shape\n",
    "        results = self.face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        landmarks = []\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for i in range(0, 468):\n",
    "                    pt1 = face_landmarks.landmark[i]\n",
    "                    x, y = int(pt1.x * w), int(pt1.y * h)\n",
    "                    landmarks.append([x, y])\n",
    "            return np.array(landmarks)\n",
    "        return None\n",
    "\n",
    "    def calibrate_thresholds(self, frame):\n",
    "        \"\"\"Calibrate EAR and MAR thresholds based on initial frames.\"\"\"\n",
    "        landmarks = self.extract_landmarks(frame)\n",
    "\n",
    "        # Ensure all required landmarks are present before attempting to access them\n",
    "        if landmarks is not None and len(landmarks) > max(max(self.LEFT_EYE), max(self.RIGHT_EYE), max(self.MOUTH)):\n",
    "            left_eye = np.array([landmarks[i] for i in self.LEFT_EYE])\n",
    "            right_eye = np.array([landmarks[i] for i in self.RIGHT_EYE])\n",
    "            mouth = np.array([landmarks[i] for i in self.MOUTH])\n",
    "            \n",
    "            ear = (self.eye_aspect_ratio(left_eye) + self.eye_aspect_ratio(right_eye)) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "\n",
    "            self.CALIBRATION_EAR_SAMPLES.append(ear)\n",
    "            self.CALIBRATION_MAR_SAMPLES.append(mar)\n",
    "            self.calibration_frames_collected += 1\n",
    "\n",
    "            cv2.putText(frame, \"CALIBRATING... Please look at camera\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Frames: {self.calibration_frames_collected}\", (50, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            if self.calibration_frames_collected >= self.CALIBRATION_DURATION_SECONDS * 30: # Assuming 30 FPS\n",
    "                self.baseline_ear = np.mean(self.CALIBRATION_EAR_SAMPLES)\n",
    "                self.baseline_mar = np.mean(self.CALIBRATION_MAR_SAMPLES)\n",
    "                \n",
    "                # Set dynamic thresholds based on baseline. These values can be fine-tuned.\n",
    "                self.EYE_AR_THRESH = self.baseline_ear * 0.75 # 25% drop from baseline\n",
    "                self.MOUTH_AR_THRESH = self.baseline_mar * 1.25 # 25% increase from baseline\n",
    "                \n",
    "                self.calibration_complete = True\n",
    "                print(f\"Calibration complete. Baseline EAR: {self.baseline_ear:.2f}, New EAR Thresh: {self.EYE_AR_THRESH:.2f}\")\n",
    "                print(f\"Baseline MAR: {self.baseline_mar:.2f}, New MAR Thresh: {self.MOUTH_AR_THRESH:.2f}\")\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected for calibration!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        return self.calibration_complete\n",
    "\n",
    "    def drowsiness_monitoring(self, frame):\n",
    "        \"\"\"Handle drowsiness monitoring phase\"\"\"\n",
    "        landmarks = self.extract_landmarks(frame)\n",
    "        \n",
    "        if landmarks is not None and len(landmarks) > max(max(self.LEFT_EYE), max(self.RIGHT_EYE), max(self.MOUTH)):\n",
    "            # Extract eye and mouth coordinates\n",
    "            left_eye = np.array([landmarks[i] for i in self.LEFT_EYE])\n",
    "            right_eye = np.array([landmarks[i] for i in self.RIGHT_EYE])\n",
    "            mouth = np.array([landmarks[i] for i in self.MOUTH])\n",
    "            \n",
    "            # Calculate aspect ratios\n",
    "            left_ear = self.eye_aspect_ratio(left_eye)\n",
    "            right_ear = self.eye_aspect_ratio(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "\n",
    "            self.ear_history.append(ear)\n",
    "            \n",
    "            # Draw contours\n",
    "            # MediaPipe drawing utilities can be used for more sophisticated drawing\n",
    "            # For simplicity, we'll draw convex hulls using OpenCV for now\n",
    "            cv2.drawContours(frame, [cv2.convexHull(left_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(right_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Drowsiness detection (EAR)\n",
    "            if ear < self.EYE_AR_THRESH:\n",
    "                self.eye_counter += 1\n",
    "                self.blink_duration_frames += 1\n",
    "                if self.eye_counter >= self.EYE_AR_CONSEC_FRAMES:\n",
    "                    if not self.drowsy_alert:\n",
    "                        self.drowsy_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                if self.eye_counter > 0: # Eye just opened after being closed\n",
    "                    # Check for blink duration (a normal blink is usually 3-5 frames)\n",
    "                    if self.blink_duration_frames > 2 and self.blink_duration_frames < 15: # Avoid very short noise and very long closures\n",
    "                        self.blink_count += 1\n",
    "                        self.last_blink_time = time.time()\n",
    "                self.eye_counter = 0\n",
    "                self.blink_duration_frames = 0\n",
    "                self.drowsy_alert = False\n",
    "            \n",
    "            # Yawning detection\n",
    "            if mar > self.MOUTH_AR_THRESH:\n",
    "                self.yawn_counter += 1\n",
    "                if self.yawn_counter >= self.YAWN_CONSEC_FRAMES:\n",
    "                    if not self.yawn_alert:\n",
    "                        self.yawn_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                self.yawn_counter = 0\n",
    "                self.yawn_alert = False\n",
    "            \n",
    "            # Calculate PERCLOS (Percentage of Eyelid Closure Over the Pupil Over Time)\n",
    "            perclos = 0.0\n",
    "            if len(self.ear_history) > 0:\n",
    "                closed_frames = sum(1 for e in self.ear_history if e < self.EYE_AR_THRESH)\n",
    "                perclos = (closed_frames / len(self.ear_history)) * 100\n",
    "\n",
    "            # Display metrics\n",
    "            cv2.putText(frame, f\"Driver: {self.verified_driver_name}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"EAR: {ear:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"MAR: {mar:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"PERCLOS: {perclos:.1f}%\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Blinks: {self.blink_count}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Alert messages\n",
    "            if self.drowsy_alert:\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "                cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 10)\n",
    "            \n",
    "            if self.yawn_alert:\n",
    "                cv2.putText(frame, \"YAWNING DETECTED!\", (10, 220), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 3)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected for drowsiness monitoring!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    def run_system(self, video_path=None, output_video_path=None):\n",
    "        \"\"\"Main system loop\"\"\"\n",
    "        if video_path:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video stream or file.\")\n",
    "            return\n",
    "\n",
    "        # Initialize VideoWriter only if output_video_path is provided\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        print(\"\\n=== INTEGRATED DRIVER SAFETY SYSTEM ===\")\n",
    "        print(\"Phase 1: Security Verification (Bypassed)\")\n",
    "        print(\"Phase 2: Drowsiness Monitoring\")\n",
    "        if video_path:\n",
    "            print(f\"Processing video: {video_path}\")\n",
    "        else:\n",
    "            print(\"Using webcam for live feed.\")\n",
    "        if output_video_path:\n",
    "            print(f\"Output video will be saved to: {output_video_path}\")\n",
    "        print(f\"Alert sound: {self.mp3_file}\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream or file.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1) # Mirror image\n",
    "\n",
    "            if not self.security_verified:\n",
    "                # This block is currently bypassed.\n",
    "                self.security_verification(frame)\n",
    "            elif not self.calibration_complete:\n",
    "                self.calibrate_thresholds(frame)\n",
    "            else:\n",
    "                self.drowsiness_monitoring(frame)\n",
    "\n",
    "            cv2.imshow(\"Driver Safety System\", frame)\n",
    "\n",
    "            # Write the processed frame to the output video file if writer is initialized\n",
    "            if out:\n",
    "                out.write(frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        if out:\n",
    "            out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\nDriver Safety System terminated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # To use webcam, call run_system() without arguments or with video_path=None\n",
    "    # To process a video file, provide the path: system.run_system(\"path/to/your/video.mp4\")\n",
    "    # To save output to a video fiqle, provide output_video_path: system.run_system(output_video_path=\"output.mp4\")\n",
    "    system = IntegratedDriverSafetySystem()\n",
    "    system.run_system()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac1d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "991815e0",
   "metadata": {},
   "source": [
    "## 2nd Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d3d68d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "WARNING:tensorflow:From c:\\Users\\ahmedhoss\\anaconda3\\envs\\Py_11\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Loading authorized drivers from Images_sec...\n",
      "Loaded: Ahmed\n",
      "Loaded: Bill\n",
      "Loaded: Elon\n",
      "Loaded: Mohamed Ali\n",
      "Drowsiness detection system initialized with MediaPipe Face Mesh\n",
      "Audio system ready - Using: Untitled (1).mp3\n",
      "\n",
      "=== INTEGRATED DRIVER SAFETY SYSTEM ===\n",
      "Phase 1: Security Verification\n",
      "Phase 2: Drowsiness Monitoring\n",
      "Using webcam for live feed.\n",
      "Alert sound: Untitled (1).mp3\n",
      "Calibration complete. Baseline EAR: 1.38, New EAR Thresh: 1.03\n",
      "Baseline MAR: 1.19, New MAR Thresh: 1.48\n",
      "\n",
      "Driver Safety System terminated.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Integrated Driver Security and Drowsiness Detection System\n",
    "\n",
    "This system combines:\n",
    "1. Face recognition security verification (runs first)\n",
    "2. Driver drowsiness and yawning detection (runs after security verification)\n",
    "\n",
    "Requirements:\n",
    "1. Install packages: pip install opencv-python numpy scipy pygame mediapipe face_recognition\n",
    "2. Create 'Images_sec' folder with authorized driver photos (e.g., Ahmed.jpg, Bill.jpeg, etc.)\n",
    "3. Place your MP3 alert file \"Untitled (1).mp3\" in the same directory\n",
    "4. Ensure webcam is connected and working\n",
    "\n",
    "Usage:\n",
    "- Run the script and position your face clearly in front of the camera\n",
    "- First, the security system will verify your identity (needs 2 consecutive verifications)\n",
    "- After successful verification, drowsiness monitoring begins automatically\n",
    "- The system will play \"Untitled (1).mp3\" when drowsiness or yawning is detected\n",
    "- Press 'q' to quit at any time\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import pygame\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "import mediapipe as mp\n",
    "import face_recognition # Import face_recognition library\n",
    "\n",
    "class IntegratedDriverSafetySystem:\n",
    "    def __init__(self, security_images_path=\"Images_sec\", mp3_filename=\"Untitled (1).mp3\"):\n",
    "        # Security system initialization\n",
    "        self.security_images_path = security_images_path\n",
    "        self.authorized_drivers = [] # This will store face encodings\n",
    "        self.driver_names = []\n",
    "        self.load_authorized_drivers() # Load authorized drivers\n",
    "        \n",
    "        # Drowsiness detection initialization\n",
    "        self.face_mesh = None\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.init_drowsiness_detector()\n",
    "        \n",
    "        # System state\n",
    "        self.security_verified = False # Set to False initially\n",
    "        self.verified_driver_name = \"Unknown\"\n",
    "        self.consecutive_verifications = 0\n",
    "        self.last_verified_name = \"\"\n",
    "        \n",
    "        # Audio setup\n",
    "        self.mp3_file = mp3_filename\n",
    "        self.setup_audio()\n",
    "        \n",
    "        # Drowsiness detection parameters (MediaPipe indices)\n",
    "        # These indices are for the 468 landmarks provided by MediaPipe Face Mesh\n",
    "        # Left eye landmarks (approximate, based on common EAR implementations)\n",
    "        self.LEFT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "        self.RIGHT_EYE = [133, 173, 157, 158, 159, 160, 161, 246, 7, 33, 163, 144, 145, 153, 154, 155]\n",
    "        # Mouth landmarks (approximate, for MAR calculation)\n",
    "        self.MOUTH = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 309]\n",
    "\n",
    "        # Thresholds (initial values, will be dynamically adjusted)\n",
    "        self.EYE_AR_THRESH = 0.25\n",
    "        self.MOUTH_AR_THRESH = 0.7\n",
    "        self.EYE_AR_CONSEC_FRAMES = 20\n",
    "        self.YAWN_CONSEC_FRAMES = 15\n",
    "        \n",
    "        # Counters for drowsiness detection\n",
    "        self.eye_counter = 0\n",
    "        self.yawn_counter = 0\n",
    "        self.drowsy_alert = False\n",
    "        self.yawn_alert = False\n",
    "\n",
    "        # New attributes for dynamic thresholding and temporal analysis\n",
    "        self.baseline_ear = None\n",
    "        self.baseline_mar = None\n",
    "        self.ear_history = deque(maxlen=60) # Store last 60 EAR values (approx 2 seconds at 30 FPS)\n",
    "        self.blink_duration_frames = 0\n",
    "        self.blink_count = 0\n",
    "        self.last_blink_time = time.time()\n",
    "        self.calibration_complete = False\n",
    "        self.calibration_frames_collected = 0\n",
    "        self.CALIBRATION_DURATION_SECONDS = 5 # Calibrate for 5 seconds\n",
    "        self.CALIBRATION_EAR_SAMPLES = []\n",
    "        self.CALIBRATION_MAR_SAMPLES = []\n",
    "\n",
    "    def load_authorized_drivers(self):\n",
    "        \"\"\"Load and encode authorized driver faces\"\"\"\n",
    "        print(f\"Loading authorized drivers from {self.security_images_path}...\")\n",
    "        if not os.path.exists(self.security_images_path):\n",
    "            print(f\"Warning: Security images path '{self.security_images_path}' does not exist. Security verification will not function.\")\n",
    "            return\n",
    "\n",
    "        for filename in os.listdir(self.security_images_path):\n",
    "            if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_path = os.path.join(self.security_images_path, filename)\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "                \n",
    "                if len(face_encodings) > 0:\n",
    "                    self.authorized_drivers.append(face_encodings[0])\n",
    "                    self.driver_names.append(os.path.splitext(filename)[0]) # Use filename as name\n",
    "                    print(f\"Loaded: {os.path.splitext(filename)[0]}\")\n",
    "                else:\n",
    "                    print(f\"No face found in {filename}\")\n",
    "        if not self.authorized_drivers:\n",
    "            print(\"No authorized drivers loaded. Security verification will be skipped.\")\n",
    "    \n",
    "    def init_drowsiness_detector(self):\n",
    "        \"\"\"Initialize MediaPipe Face Mesh for drowsiness detection\"\"\"\n",
    "        try:\n",
    "            self.face_mesh = self.mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "            print(\"Drowsiness detection system initialized with MediaPipe Face Mesh\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing drowsiness detector with MediaPipe: {e}\")\n",
    "            print(\"Make sure MediaPipe is installed and working correctly.\")\n",
    "    \n",
    "    def setup_audio(self):\n",
    "        \"\"\"Setup audio system for alerts\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.alert_sound = pygame.mixer.Sound(self.mp3_file)\n",
    "            print(f\"Audio system ready - Using: {self.mp3_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Audio setup failed: {e}\")\n",
    "            print(\"Will use system beep as fallback\")\n",
    "            self.alert_sound = None\n",
    "    \n",
    "    def play_alert(self):\n",
    "        \"\"\"Play alert sound\"\"\"\n",
    "        if self.alert_sound:\n",
    "            self.alert_sound.play()\n",
    "        else:\n",
    "            print('\\a')  # System beep\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    def security_verification(self, frame):\n",
    "        \"\"\"Handle security verification phase\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        verified_current_frame = False\n",
    "        current_frame_name = \"Unknown\"\n",
    "\n",
    "        if not self.authorized_drivers:\n",
    "            cv2.putText(frame, \"NO AUTHORIZED DRIVERS LOADED!\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Add images to Images_sec folder.\", (50, 80), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            return False\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(self.authorized_drivers, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(self.authorized_drivers, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = self.driver_names[best_match_index]\n",
    "                current_frame_name = name\n",
    "                verified_current_frame = True\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0) if verified_current_frame else (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0) if verified_current_frame else (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "        if verified_current_frame and current_frame_name == self.last_verified_name:\n",
    "            self.consecutive_verifications += 1\n",
    "            if self.consecutive_verifications >= 2: # Needs 2 consecutive verifications\n",
    "                self.security_verified = True\n",
    "                self.verified_driver_name = current_frame_name\n",
    "                cv2.putText(frame, f\"VERIFIED: {self.verified_driver_name}\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Drowsiness monitoring starting...\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, f\"Verifying: {current_frame_name} ({self.consecutive_verifications}/2)\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        else:\n",
    "            self.consecutive_verifications = 0\n",
    "            self.last_verified_name = current_frame_name\n",
    "            cv2.putText(frame, \"UNAUTHORIZED!\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Please verify your identity.\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "        return self.security_verified\n",
    "    \n",
    "    def eye_aspect_ratio(self, eye):\n",
    "        \"\"\"Calculate eye aspect ratio\"\"\"\n",
    "        # Compute the Euclidean distances between the two sets of\n",
    "        # vertical eye landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        # Compute the Euclidean distance between the horizontal\n",
    "        # eye landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "    \n",
    "    def mouth_aspect_ratio(self, mouth):\n",
    "        \"\"\"Calculate mouth aspect ratio\"\"\"\n",
    "        # Compute the Euclidean distances between the two sets of\n",
    "        # vertical mouth landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(mouth[2], mouth[10])\n",
    "        B = dist.euclidean(mouth[4], mouth[8])\n",
    "        # Compute the Euclidean distance between the horizontal\n",
    "        # mouth landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(mouth[0], mouth[6])\n",
    "        # Compute the mouth aspect ratio\n",
    "        mar = (A + B) / (2.0 * C)\n",
    "        return mar\n",
    "    \n",
    "    def extract_landmarks(self, frame):\n",
    "        \"\"\"Extract facial landmarks using MediaPipe Face Mesh\"\"\"\n",
    "        h, w, c = frame.shape\n",
    "        results = self.face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        landmarks = []\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for i in range(0, 468):\n",
    "                    pt1 = face_landmarks.landmark[i]\n",
    "                    x, y = int(pt1.x * w), int(pt1.y * h)\n",
    "                    landmarks.append([x, y])\n",
    "            return np.array(landmarks)\n",
    "        return None\n",
    "\n",
    "    def calibrate_thresholds(self, frame):\n",
    "        \"\"\"Calibrate EAR and MAR thresholds based on initial frames.\"\"\"\n",
    "        landmarks = self.extract_landmarks(frame)\n",
    "\n",
    "        # Ensure all required landmarks are present before attempting to access them\n",
    "        if landmarks is not None and len(landmarks) > max(max(self.LEFT_EYE), max(self.RIGHT_EYE), max(self.MOUTH)):\n",
    "            left_eye = np.array([landmarks[i] for i in self.LEFT_EYE])\n",
    "            right_eye = np.array([landmarks[i] for i in self.RIGHT_EYE])\n",
    "            mouth = np.array([landmarks[i] for i in self.MOUTH])\n",
    "            \n",
    "            ear = (self.eye_aspect_ratio(left_eye) + self.eye_aspect_ratio(right_eye)) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "\n",
    "            self.CALIBRATION_EAR_SAMPLES.append(ear)\n",
    "            self.CALIBRATION_MAR_SAMPLES.append(mar)\n",
    "            self.calibration_frames_collected += 1\n",
    "\n",
    "            cv2.putText(frame, \"CALIBRATING... Please look at camera\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Frames: {self.calibration_frames_collected}\", (50, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            if self.calibration_frames_collected >= self.CALIBRATION_DURATION_SECONDS * 30: # Assuming 30 FPS\n",
    "                self.baseline_ear = np.mean(self.CALIBRATION_EAR_SAMPLES)\n",
    "                self.baseline_mar = np.mean(self.CALIBRATION_MAR_SAMPLES)\n",
    "                \n",
    "                # Set dynamic thresholds based on baseline. These values can be fine-tuned.\n",
    "                self.EYE_AR_THRESH = self.baseline_ear * 0.75 # 25% drop from baseline\n",
    "                self.MOUTH_AR_THRESH = self.baseline_mar * 1.25 # 25% increase from baseline\n",
    "                \n",
    "                self.calibration_complete = True\n",
    "                print(f\"Calibration complete. Baseline EAR: {self.baseline_ear:.2f}, New EAR Thresh: {self.EYE_AR_THRESH:.2f}\")\n",
    "                print(f\"Baseline MAR: {self.baseline_mar:.2f}, New MAR Thresh: {self.MOUTH_AR_THRESH:.2f}\")\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected for calibration!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        return self.calibration_complete\n",
    "\n",
    "    def drowsiness_monitoring(self, frame):\n",
    "        \"\"\"Handle drowsiness monitoring phase\"\"\"\n",
    "        landmarks = self.extract_landmarks(frame)\n",
    "        \n",
    "        if landmarks is not None and len(landmarks) > max(max(self.LEFT_EYE), max(self.RIGHT_EYE), max(self.MOUTH)):\n",
    "            # Extract eye and mouth coordinates\n",
    "            left_eye = np.array([landmarks[i] for i in self.LEFT_EYE])\n",
    "            right_eye = np.array([landmarks[i] for i in self.RIGHT_EYE])\n",
    "            mouth = np.array([landmarks[i] for i in self.MOUTH])\n",
    "            \n",
    "            # Calculate aspect ratios\n",
    "            left_ear = self.eye_aspect_ratio(left_eye)\n",
    "            right_ear = self.eye_aspect_ratio(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "\n",
    "            self.ear_history.append(ear)\n",
    "            \n",
    "            # Draw contours\n",
    "            # MediaPipe drawing utilities can be used for more sophisticated drawing\n",
    "            # For simplicity, we'll draw convex hulls using OpenCV for now\n",
    "            cv2.drawContours(frame, [cv2.convexHull(left_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(right_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Drowsiness detection (EAR)\n",
    "            if ear < self.EYE_AR_THRESH:\n",
    "                self.eye_counter += 1\n",
    "                self.blink_duration_frames += 1\n",
    "                if self.eye_counter >= self.EYE_AR_CONSEC_FRAMES:\n",
    "                    if not self.drowsy_alert:\n",
    "                        self.drowsy_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                if self.eye_counter > 0: # Eye just opened after being closed\n",
    "                    # Check for blink duration (a normal blink is usually 3-5 frames)\n",
    "                    if self.blink_duration_frames > 2 and self.blink_duration_frames < 15: # Avoid very short noise and very long closures\n",
    "                        self.blink_count += 1\n",
    "                        self.last_blink_time = time.time()\n",
    "                self.eye_counter = 0\n",
    "                self.blink_duration_frames = 0\n",
    "                self.drowsy_alert = False\n",
    "            \n",
    "            # Yawning detection\n",
    "            if mar > self.MOUTH_AR_THRESH:\n",
    "                self.yawn_counter += 1\n",
    "                if self.yawn_counter >= self.YAWN_CONSEC_FRAMES:\n",
    "                    if not self.yawn_alert:\n",
    "                        self.yawn_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                self.yawn_counter = 0\n",
    "                self.yawn_alert = False\n",
    "            \n",
    "            # Calculate PERCLOS (Percentage of Eyelid Closure Over the Pupil Over Time)\n",
    "            perclos = 0.0\n",
    "            if len(self.ear_history) > 0:\n",
    "                closed_frames = sum(1 for e in self.ear_history if e < self.EYE_AR_THRESH)\n",
    "                perclos = (closed_frames / len(self.ear_history)) * 100\n",
    "\n",
    "            # Display metrics\n",
    "            cv2.putText(frame, f\"Driver: {self.verified_driver_name}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"EAR: {ear:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"MAR: {mar:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"PERCLOS: {perclos:.1f}%\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Blinks: {self.blink_count}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Alert messages\n",
    "            if self.drowsy_alert:\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "                cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 10)\n",
    "            \n",
    "            if self.yawn_alert:\n",
    "                cv2.putText(frame, \"YAWNING DETECTED!\", (10, 220), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 3)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected for drowsiness monitoring!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    def run_system(self, video_path=None, output_video_path=None):\n",
    "        \"\"\"Main system loop\"\"\"\n",
    "        if video_path:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video stream or file.\")\n",
    "            return\n",
    "\n",
    "        # Initialize VideoWriter only if output_video_path is provided\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        print(\"\\n=== INTEGRATED DRIVER SAFETY SYSTEM ===\")\n",
    "        print(\"Phase 1: Security Verification\")\n",
    "        print(\"Phase 2: Drowsiness Monitoring\")\n",
    "        if video_path:\n",
    "            print(f\"Processing video: {video_path}\")\n",
    "        else:\n",
    "            print(\"Using webcam for live feed.\")\n",
    "        if output_video_path:\n",
    "            print(f\"Output video will be saved to: {output_video_path}\")\n",
    "        print(f\"Alert sound: {self.mp3_file}\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream or file.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1) # Mirror image\n",
    "\n",
    "            if not self.security_verified:\n",
    "                self.security_verification(frame)\n",
    "            elif not self.calibration_complete:\n",
    "                self.calibrate_thresholds(frame)\n",
    "            else:\n",
    "                self.drowsiness_monitoring(frame)\n",
    "\n",
    "            cv2.imshow(\"Driver Safety System\", frame)\n",
    "\n",
    "            # Write the processed frame to the output video file if writer is initialized\n",
    "            if out:\n",
    "                out.write(frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        if out:\n",
    "            out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\nDriver Safety System terminated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # To use webcam, call run_system() without arguments or with video_path=None\n",
    "    # To process a video file, provide the path: system.run_system(\"path/to/your/video.mp4\")\n",
    "    # To save output to a video file, provide output_video_path: system.run_system(output_video_path=\"output.mp4\")\n",
    "    system = IntegratedDriverSafetySystem()\n",
    "    system.run_system()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1f2ff8",
   "metadata": {},
   "source": [
    "## 3rd Mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff632b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading authorized drivers from Images_sec...\n",
      "Loaded: Ahmed\n",
      "Loaded: Bill\n",
      "Loaded: Elon\n",
      "Loaded: Mohamed Ali\n",
      "Drowsiness detection system initialized with MediaPipe Face Mesh\n",
      "Audio system ready - Using: Untitled (1).mp3\n",
      "\n",
      "=== INTEGRATED DRIVER SAFETY SYSTEM ===\n",
      "Phase 1: Security Verification\n",
      "Phase 2: Drowsiness Monitoring\n",
      "Using webcam for live feed.\n",
      "Alert sound: Untitled (1).mp3\n",
      "Calibration complete. Baseline EAR: 1.33, New EAR Thresh: 1.00\n",
      "Baseline MAR: 2.55, New MAR Thresh: 3.19\n",
      "\n",
      "Driver Safety System terminated.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Integrated Driver Security and Drowsiness Detection System\n",
    "\n",
    "This system combines:\n",
    "1. Face recognition security verification (runs first)\n",
    "2. Driver drowsiness and yawning detection (runs after security verification)\n",
    "\n",
    "Requirements:\n",
    "1. Install packages: pip install opencv-python numpy scipy pygame mediapipe face_recognition\n",
    "2. Create 'Images_sec' folder with authorized driver photos (e.g., Ahmed.jpg, Bill.jpeg, etc.)\n",
    "3. Place your MP3 alert file \"Untitled (1).mp3\" in the same directory\n",
    "4. Ensure webcam is connected and working\n",
    "\n",
    "Usage:\n",
    "- Run the script and position your face clearly in front of the camera\n",
    "- First, the security system will verify your identity (needs 2 consecutive verifications)\n",
    "- After successful verification, drowsiness monitoring begins automatically\n",
    "- The system will play \"Untitled (1).mp3\" when drowsiness or yawning is detected\n",
    "- Press 'q' to quit at any time\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import pygame\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "from collections import deque\n",
    "import mediapipe as mp\n",
    "import face_recognition # Import face_recognition library\n",
    "\n",
    "class IntegratedDriverSafetySystem:\n",
    "    def __init__(self, security_images_path=\"Images_sec\", mp3_filename=\"Untitled (1).mp3\"):\n",
    "        # Security system initialization\n",
    "        self.security_images_path = security_images_path\n",
    "        self.authorized_drivers = [] # This will store face encodings\n",
    "        self.driver_names = []\n",
    "        self.load_authorized_drivers() # Load authorized drivers\n",
    "        \n",
    "        # Drowsiness detection initialization\n",
    "        self.face_mesh = None\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh\n",
    "        self.init_drowsiness_detector()\n",
    "        \n",
    "        # System state\n",
    "        self.security_verified = False # Set to False initially\n",
    "        self.verified_driver_name = \"Unknown\"\n",
    "        self.consecutive_verifications = 0\n",
    "        self.last_verified_name = \"\"\n",
    "        \n",
    "        # Audio setup\n",
    "        self.mp3_file = mp3_filename\n",
    "        self.setup_audio()\n",
    "        \n",
    "        # Drowsiness detection parameters (MediaPipe indices)\n",
    "        # These indices are for the 468 landmarks provided by MediaPipe Face Mesh\n",
    "        # Left eye landmarks (approximate, based on common EAR implementations)\n",
    "        self.LEFT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "        self.RIGHT_EYE = [133, 173, 157, 158, 159, 160, 161, 246, 7, 33, 163, 144, 145, 153, 154, 155]\n",
    "        \n",
    "        # Mouth landmarks for MAR calculation (more standard 6 points for MAR)\n",
    "        # These are approximate indices for the inner and outer mouth corners from MediaPipe's 468 landmarks\n",
    "        # Using a common set of 6 points for MAR: 13, 14, 78, 81, 308, 311\n",
    "        self.MOUTH = [13, 14, 78, 81, 308, 311] # Updated indices for MAR calculation\n",
    "\n",
    "        # Thresholds (initial values, will be dynamically adjusted)\n",
    "        self.EYE_AR_THRESH = 0.25\n",
    "        self.MOUTH_AR_THRESH = 0.7 # Will be dynamically adjusted, this is a fallback\n",
    "        self.EYE_AR_CONSEC_FRAMES = 20\n",
    "        self.YAWN_CONSEC_FRAMES = 15\n",
    "        \n",
    "        # Counters for drowsiness detection\n",
    "        self.eye_counter = 0\n",
    "        self.yawn_counter = 0\n",
    "        self.drowsy_alert = False\n",
    "        self.yawn_alert = False\n",
    "\n",
    "        # New attributes for dynamic thresholding and temporal analysis\n",
    "        self.baseline_ear = None\n",
    "        self.baseline_mar = None\n",
    "        self.ear_history = deque(maxlen=60) # Store last 60 EAR values (approx 2 seconds at 30 FPS)\n",
    "        self.blink_duration_frames = 0\n",
    "        self.blink_count = 0\n",
    "        self.last_blink_time = time.time()\n",
    "        self.calibration_complete = False\n",
    "        self.calibration_frames_collected = 0\n",
    "        self.CALIBRATION_DURATION_SECONDS = 5 # Calibrate for 5 seconds\n",
    "        self.CALIBRATION_EAR_SAMPLES = []\n",
    "        self.CALIBRATION_MAR_SAMPLES = []\n",
    "\n",
    "    def load_authorized_drivers(self):\n",
    "        \"\"\"Load and encode authorized driver faces\"\"\"\n",
    "        print(f\"Loading authorized drivers from {self.security_images_path}...\")\n",
    "        if not os.path.exists(self.security_images_path):\n",
    "            print(f\"Warning: Security images path '{self.security_images_path}' does not exist. Security verification will not function.\")\n",
    "            return\n",
    "\n",
    "        for filename in os.listdir(self.security_images_path):\n",
    "            if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                image_path = os.path.join(self.security_images_path, filename)\n",
    "                image = face_recognition.load_image_file(image_path)\n",
    "                face_encodings = face_recognition.face_encodings(image)\n",
    "                \n",
    "                if len(face_encodings) > 0:\n",
    "                    self.authorized_drivers.append(face_encodings[0])\n",
    "                    self.driver_names.append(os.path.splitext(filename)[0]) # Use filename as name\n",
    "                    print(f\"Loaded: {os.path.splitext(filename)[0]}\")\n",
    "                else:\n",
    "                    print(f\"No face found in {filename}\")\n",
    "        if not self.authorized_drivers:\n",
    "            print(\"No authorized drivers loaded. Security verification will be skipped.\")\n",
    "    \n",
    "    def init_drowsiness_detector(self):\n",
    "        \"\"\"Initialize MediaPipe Face Mesh for drowsiness detection\"\"\"\n",
    "        try:\n",
    "            self.face_mesh = self.mp_face_mesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "            print(\"Drowsiness detection system initialized with MediaPipe Face Mesh\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error initializing drowsiness detector with MediaPipe: {e}\")\n",
    "            print(\"Make sure MediaPipe is installed and working correctly.\")\n",
    "    \n",
    "    def setup_audio(self):\n",
    "        \"\"\"Setup audio system for alerts\"\"\"\n",
    "        try:\n",
    "            pygame.mixer.init()\n",
    "            self.alert_sound = pygame.mixer.Sound(self.mp3_file)\n",
    "            print(f\"Audio system ready - Using: {self.mp3_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Audio setup failed: {e}\")\n",
    "            print(\"Will use system beep as fallback\")\n",
    "            self.alert_sound = None\n",
    "    \n",
    "    def play_alert(self):\n",
    "        \"\"\"Play alert sound\"\"\"\n",
    "        if self.alert_sound:\n",
    "            self.alert_sound.play()\n",
    "        else:\n",
    "            print('\\a')  # System beep\n",
    "            sys.stdout.flush()\n",
    "    \n",
    "    def security_verification(self, frame):\n",
    "        \"\"\"Handle security verification phase\"\"\"\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_encodings = face_recognition.face_encodings(rgb_frame, face_locations)\n",
    "\n",
    "        verified_current_frame = False\n",
    "        current_frame_name = \"Unknown\"\n",
    "\n",
    "        if not self.authorized_drivers:\n",
    "            cv2.putText(frame, \"NO AUTHORIZED DRIVERS LOADED!\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Add images to Images_sec folder.\", (50, 80), cv2.FONT_HERSHEY_COMPLEX, 0.6, (0, 0, 255), 2)\n",
    "            return False\n",
    "\n",
    "        for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "            matches = face_recognition.compare_faces(self.authorized_drivers, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "\n",
    "            face_distances = face_recognition.face_distance(self.authorized_drivers, face_encoding)\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            if matches[best_match_index]:\n",
    "                name = self.driver_names[best_match_index]\n",
    "                current_frame_name = name\n",
    "                verified_current_frame = True\n",
    "\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0) if verified_current_frame else (0, 0, 255), 2)\n",
    "            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 255, 0) if verified_current_frame else (0, 0, 255), cv2.FILLED)\n",
    "            font = cv2.FONT_HERSHEY_DUPLEX\n",
    "            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.7, (255, 255, 255), 1)\n",
    "\n",
    "        if verified_current_frame and current_frame_name == self.last_verified_name:\n",
    "            self.consecutive_verifications += 1\n",
    "            if self.consecutive_verifications >= 2: # Needs 2 consecutive verifications\n",
    "                self.security_verified = True\n",
    "                self.verified_driver_name = current_frame_name\n",
    "                cv2.putText(frame, f\"VERIFIED: {self.verified_driver_name}\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "                cv2.putText(frame, \"Drowsiness monitoring starting...\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            else:\n",
    "                cv2.putText(frame, f\"Verifying: {current_frame_name} ({self.consecutive_verifications}/2)\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
    "        else:\n",
    "            self.consecutive_verifications = 0\n",
    "            self.last_verified_name = current_frame_name\n",
    "            cv2.putText(frame, \"UNAUTHORIZED!\", (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, \"Please verify your identity.\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    def eye_aspect_ratio(self, eye):\n",
    "        \"\"\"Calculate eye aspect ratio\"\"\"\n",
    "        # Compute the Euclidean distances between the two sets of\n",
    "        # vertical eye landmarks (x, y)-coordinates\n",
    "        A = dist.euclidean(eye[1], eye[5])\n",
    "        B = dist.euclidean(eye[2], eye[4])\n",
    "        # Compute the Euclidean distance between the horizontal\n",
    "        # eye landmark (x, y)-coordinates\n",
    "        C = dist.euclidean(eye[0], eye[3])\n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (A + B) / (2.0 * C)\n",
    "        return ear\n",
    "    \n",
    "    def mouth_aspect_ratio(self, mouth):\n",
    "        \"\"\"Calculate mouth aspect ratio (MAR)\"\"\"\n",
    "        # Using 6 points: 2 vertical, 2 horizontal\n",
    "        # A: 13 (upper inner lip) to 14 (lower inner lip)\n",
    "        # B: 78 (upper outer lip) to 81 (lower outer lip)\n",
    "        # C: 308 (left mouth corner) to 311 (right mouth corner)\n",
    "        \n",
    "        # Vertical distances\n",
    "        A = dist.euclidean(mouth[1], mouth[5]) # 14 to 311 (vertical inner)\n",
    "        B = dist.euclidean(mouth[2], mouth[4]) # 78 to 308 (vertical outer)\n",
    "        \n",
    "        # Horizontal distance\n",
    "        C = dist.euclidean(mouth[0], mouth[3]) # 13 to 81 (horizontal)\n",
    "        \n",
    "        # Calculate MAR\n",
    "        mar = (A + B) / (2.0 * C)\n",
    "        return mar\n",
    "    \n",
    "    def extract_landmarks(self, frame):\n",
    "        \"\"\"Extract facial landmarks using MediaPipe Face Mesh\"\"\"\n",
    "        h, w, c = frame.shape\n",
    "        results = self.face_mesh.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        landmarks = []\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                for i in range(0, 468):\n",
    "                    pt1 = face_landmarks.landmark[i]\n",
    "                    x, y = int(pt1.x * w), int(pt1.y * h)\n",
    "                    landmarks.append([x, y])\n",
    "            return np.array(landmarks)\n",
    "        return None\n",
    "\n",
    "    def calibrate_thresholds(self, frame):\n",
    "        \"\"\"Calibrate EAR and MAR thresholds based on initial frames.\"\"\"\n",
    "        landmarks = self.extract_landmarks(frame)\n",
    "\n",
    "        # Ensure all required landmarks are present before attempting to access them\n",
    "        if landmarks is not None and len(landmarks) > max(max(self.LEFT_EYE), max(self.RIGHT_EYE), max(self.MOUTH)):\n",
    "            left_eye = np.array([landmarks[i] for i in self.LEFT_EYE])\n",
    "            right_eye = np.array([landmarks[i] for i in self.RIGHT_EYE])\n",
    "            mouth = np.array([landmarks[i] for i in self.MOUTH])\n",
    "            \n",
    "            ear = (self.eye_aspect_ratio(left_eye) + self.eye_aspect_ratio(right_eye)) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "\n",
    "            self.CALIBRATION_EAR_SAMPLES.append(ear)\n",
    "            self.CALIBRATION_MAR_SAMPLES.append(mar)\n",
    "            self.calibration_frames_collected += 1\n",
    "\n",
    "            cv2.putText(frame, \"CALIBRATING... Please look at camera\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)\n",
    "            cv2.putText(frame, f\"Frames: {self.calibration_frames_collected}\", (50, 80),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "            if self.calibration_frames_collected >= self.CALIBRATION_DURATION_SECONDS * 30: # Assuming 30 FPS\n",
    "                self.baseline_ear = np.mean(self.CALIBRATION_EAR_SAMPLES)\n",
    "                self.baseline_mar = np.mean(self.CALIBRATION_MAR_SAMPLES)\n",
    "                \n",
    "                # Set dynamic thresholds based on baseline. These values can be fine-tuned.\n",
    "                self.EYE_AR_THRESH = self.baseline_ear * 0.75 # 25% drop from baseline\n",
    "                self.MOUTH_AR_THRESH = self.baseline_mar * 1.25 # 25% increase from baseline\n",
    "                \n",
    "                self.calibration_complete = True\n",
    "                print(f\"Calibration complete. Baseline EAR: {self.baseline_ear:.2f}, New EAR Thresh: {self.EYE_AR_THRESH:.2f}\")\n",
    "                print(f\"Baseline MAR: {self.baseline_mar:.2f}, New MAR Thresh: {self.MOUTH_AR_THRESH:.2f}\")\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected for calibration!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "        return self.calibration_complete\n",
    "\n",
    "    def drowsiness_monitoring(self, frame):\n",
    "        \"\"\"Handle drowsiness monitoring phase\"\"\"\n",
    "        landmarks = self.extract_landmarks(frame)\n",
    "        \n",
    "        if landmarks is not None and len(landmarks) > max(max(self.LEFT_EYE), max(self.RIGHT_EYE), max(self.MOUTH)):\n",
    "            # Extract eye and mouth coordinates\n",
    "            left_eye = np.array([landmarks[i] for i in self.LEFT_EYE])\n",
    "            right_eye = np.array([landmarks[i] for i in self.RIGHT_EYE])\n",
    "            mouth = np.array([landmarks[i] for i in self.MOUTH])\n",
    "            \n",
    "            # Calculate aspect ratios\n",
    "            left_ear = self.eye_aspect_ratio(left_eye)\n",
    "            right_ear = self.eye_aspect_ratio(right_eye)\n",
    "            ear = (left_ear + right_ear) / 2.0\n",
    "            mar = self.mouth_aspect_ratio(mouth)\n",
    "\n",
    "            self.ear_history.append(ear)\n",
    "            \n",
    "            # Draw contours\n",
    "            # MediaPipe drawing utilities can be used for more sophisticated drawing\n",
    "            # For simplicity, we'll draw convex hulls using OpenCV for now\n",
    "            cv2.drawContours(frame, [cv2.convexHull(left_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(right_eye)], -1, (0, 255, 0), 1)\n",
    "            cv2.drawContours(frame, [cv2.convexHull(mouth)], -1, (0, 255, 0), 1)\n",
    "            \n",
    "            # Drowsiness detection (EAR)\n",
    "            if ear < self.EYE_AR_THRESH:\n",
    "                self.eye_counter += 1\n",
    "                self.blink_duration_frames += 1\n",
    "                if self.eye_counter >= self.EYE_AR_CONSEC_FRAMES:\n",
    "                    if not self.drowsy_alert:\n",
    "                        self.drowsy_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                if self.eye_counter > 0: # Eye just opened after being closed\n",
    "                    # Check for blink duration (a normal blink is usually 3-5 frames)\n",
    "                    if self.blink_duration_frames > 2 and self.blink_duration_frames < 15: # Avoid very short noise and very long closures\n",
    "                        self.blink_count += 1\n",
    "                        self.last_blink_time = time.time()\n",
    "                self.eye_counter = 0\n",
    "                self.blink_duration_frames = 0\n",
    "                self.drowsy_alert = False\n",
    "            \n",
    "            # Yawning detection\n",
    "            if mar > self.MOUTH_AR_THRESH:\n",
    "                self.yawn_counter += 1\n",
    "                if self.yawn_counter >= self.YAWN_CONSEC_FRAMES:\n",
    "                    if not self.yawn_alert:\n",
    "                        self.yawn_alert = True\n",
    "                        self.play_alert()\n",
    "            else:\n",
    "                self.yawn_counter = 0\n",
    "                self.yawn_alert = False\n",
    "            \n",
    "            # Calculate PERCLOS (Percentage of Eyelid Closure Over the Pupil Over Time)\n",
    "            perclos = 0.0\n",
    "            if len(self.ear_history) > 0:\n",
    "                closed_frames = sum(1 for e in self.ear_history if e < self.EYE_AR_THRESH)\n",
    "                perclos = (closed_frames / len(self.ear_history)) * 100\n",
    "\n",
    "            # Display metrics\n",
    "            cv2.putText(frame, f\"Driver: {self.verified_driver_name}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"EAR: {ear:.2f}\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"MAR: {mar:.2f}\", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"PERCLOS: {perclos:.1f}%\", (10, 120), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Blinks: {self.blink_count}\", (10, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Alert messages\n",
    "            if self.drowsy_alert:\n",
    "                cv2.putText(frame, \"DROWSINESS ALERT!\", (10, 180), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "                cv2.rectangle(frame, (0, 0), (frame.shape[1], frame.shape[0]), (0, 0, 255), 10)\n",
    "            \n",
    "            if self.yawn_alert:\n",
    "                cv2.putText(frame, \"YAWNING DETECTED!\", (10, 220), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 165, 255), 3)\n",
    "        else:\n",
    "            cv2.putText(frame, \"No face detected for drowsiness monitoring!\", (50, 50),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
    "\n",
    "    def run_system(self, video_path=None, output_video_path=None):\n",
    "        \"\"\"Main system loop\"\"\"\n",
    "        if video_path:\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "        else:\n",
    "            cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open video stream or file.\")\n",
    "            return\n",
    "\n",
    "        # Initialize VideoWriter only if output_video_path is provided\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "        print(\"\\n=== INTEGRATED DRIVER SAFETY SYSTEM ===\")\n",
    "        print(\"Phase 1: Security Verification\")\n",
    "        print(\"Phase 2: Drowsiness Monitoring\")\n",
    "        if video_path:\n",
    "            print(f\"Processing video: {video_path}\")\n",
    "        else:\n",
    "            print(\"Using webcam for live feed.\")\n",
    "        if output_video_path:\n",
    "            print(f\"Output video will be saved to: {output_video_path}\")\n",
    "        print(f\"Alert sound: {self.mp3_file}\")\n",
    "\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                print(\"End of video stream or file.\")\n",
    "                break\n",
    "\n",
    "            frame = cv2.flip(frame, 1) # Mirror image\n",
    "\n",
    "            if not self.security_verified:\n",
    "                self.security_verification(frame)\n",
    "            elif not self.calibration_complete:\n",
    "                self.calibrate_thresholds(frame)\n",
    "            else:\n",
    "                self.drowsiness_monitoring(frame)\n",
    "\n",
    "            cv2.imshow(\"Driver Safety System\", frame)\n",
    "\n",
    "            # Write the processed frame to the output video file if writer is initialized\n",
    "            if out:\n",
    "                out.write(frame)\n",
    "\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            if key == ord('q'):\n",
    "                break\n",
    "\n",
    "        cap.release()\n",
    "        if out:\n",
    "            out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(\"\\nDriver Safety System terminated.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # To use webcam, call run_system() without arguments or with video_path=None\n",
    "    # To process a video file, provide the path: system.run_system(\"path/to/your/video.mp4\")\n",
    "    # To save output to a video file, provide output_video_path: system.run_system(output_video_path=\"output.mp4\")\n",
    "    system = IntegratedDriverSafetySystem()\n",
    "    system.run_system()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccbf9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e7aa69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
